"""
fetch_datasets.py
ä¸‹è½½è®ºæ–‡ä½¿ç”¨çš„ 13 ä¸ª UCI å›å½’æ•°æ®é›†ï¼ˆæ’é™¤ KEELï¼‰
ä¿å­˜åˆ° data/datasets/
"""

import os
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.preprocessing import MinMaxScaler

SAVE_DIR = os.path.join("data", "datasets")
os.makedirs(SAVE_DIR, exist_ok=True)

UCI_DATASETS = [
    "Airfoil_self_noise",
    "Concrete_Compressive_Strength",
    "autoMpg",
    "Yacht_hydrodynamics",
    "qsar_aquatic_toxicity",
    "Abalone",
    "Computer_hardware",
    "Energy_efficiency",
    "wine-quality-red",
    "wine-quality-white",
    "Baseball",
    "Treasury",
    "Laser",
]

print("\n=== å¼€å§‹ä¸‹è½½ 13 ä¸ª UCI å›å½’æ•°æ®é›† ===")

for name in UCI_DATASETS:
    csv_path = os.path.join(SAVE_DIR, f"{name}.csv")

    if os.path.exists(csv_path):
        print(f"âœ… Already exists: {name}")
        continue

    print(f"ğŸ” Fetching from OpenML: {name}")
    try:
        ds = fetch_openml(name, as_frame=True, parser="pandas")
        X, y = ds.data, ds.target

        # åªä¿ç•™æ•°å€¼åˆ—
        df = pd.concat([X, y], axis=1)
        df = df.apply(pd.to_numeric, errors="coerce").dropna()

        # å½’ä¸€åŒ–
        scaler = MinMaxScaler()
        df[df.columns] = scaler.fit_transform(df[df.columns])

        df.to_csv(csv_path, index=False)
        print(f"âœ… Saved: {csv_path}")
    except Exception as e:
        print(f"âš ï¸  Skipped {name}: {e}")

print("\nğŸ¯ æ‰€æœ‰ 13 ä¸ª UCI æ•°æ®é›†å·²å‡†å¤‡å®Œæ¯•ï¼")
